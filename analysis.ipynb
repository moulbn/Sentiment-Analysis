{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "facial-junction",
   "metadata": {},
   "source": [
    "# Movie Reviews - Classification - AITAMALIK Amine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b80ad1e",
   "metadata": {},
   "source": [
    "After the creation of all our datasets, we will here apply our models. The goal is to compare Naive Bayes to SVM and Logistic Regression in terms of training and testing accuracies. We will study the most impactful words which have the biggest weight in terms of determining the class of a review. Finally, we shall also look at the causes of our models' errors, such as sarcastic reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5da8ce",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "overhead-sector",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pvml\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8791225",
   "metadata": {},
   "source": [
    "# PART 1 - Normal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-culture",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "approximate-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Loaded\n"
     ]
    }
   ],
   "source": [
    "train_data = np.loadtxt(\"train.txt.gz\")\n",
    "X_train = train_data[:, :-1]\n",
    "Y_train = train_data[:, -1]\n",
    "\n",
    "print(\"Train Data Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901adab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Loaded\n"
     ]
    }
   ],
   "source": [
    "test_data = np.loadtxt(\"test.txt.gz\")\n",
    "X_test = test_data[:, :-1]\n",
    "Y_test = test_data[:, -1]\n",
    "\n",
    "print(\"Test Data Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-forge",
   "metadata": {},
   "source": [
    "## I. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-advantage",
   "metadata": {},
   "source": [
    "### a) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "front-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nb(X, Y):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    # Positive Reviews\n",
    "    pos_counter = X[Y == 1, :].sum(0)\n",
    "    pi_pos = (1 + pos_counter) / (n + pos_counter.sum())\n",
    "    prior_pos = Y.sum() / m\n",
    "    \n",
    "    # Negative Reviews\n",
    "    neg_counter = X[Y == 0, :].sum(0)\n",
    "    pi_neg = (1 + neg_counter) / (n + neg_counter.sum())\n",
    "    prior_neg = 1 - prior_pos\n",
    "    \n",
    "    w = np.log(pi_pos) - np.log(pi_neg)\n",
    "    b = np.log(prior_pos) - np.log(prior_neg)\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complicated-contents",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained\n"
     ]
    }
   ],
   "source": [
    "nb_w, nb_b = train_nb(X_train, Y_train)\n",
    "print(\"Classifier trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-female",
   "metadata": {},
   "source": [
    "### b) Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "narrative-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_nb(X, w, b):\n",
    "    scores = X @ w + b\n",
    "    labels = (scores > 0).astype(int)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a4f02",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "exact-beauty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training Accuracy: 80.032%\n"
     ]
    }
   ],
   "source": [
    "nb_train_predictions = inference_nb(X_train, nb_w, nb_b)\n",
    "nb_train_accuracy = (nb_train_predictions == Y_train).mean()\n",
    "\n",
    "print(f\"Naive Bayes Training Accuracy: {nb_train_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75ec0f",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2afeed15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Testing Accuracy: 79.75999999999999%\n"
     ]
    }
   ],
   "source": [
    "nb_test_predictions = inference_nb(X_test, nb_w, nb_b)\n",
    "nb_test_accuracy = (nb_test_predictions == Y_test).mean()\n",
    "\n",
    "print(f\"Naive Bayes Testing Accuracy: {nb_test_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-church",
   "metadata": {},
   "source": [
    "## II. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06e35b",
   "metadata": {},
   "source": [
    "### a) Impactful Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "offshore-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"vocabulary.txt\", encoding=\"utf-8\")\n",
    "vocabulary = f.read().split()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-satisfaction",
   "metadata": {},
   "source": [
    "#### Most Impactful Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "under-council",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words Most Likely in Negative Reviews:\n",
      "\n",
      " waste: -2.6284\n",
      " worst: -2.2884\n",
      " awful: -2.0895\n",
      " poorly: -2.0768\n",
      " lame: -1.9208\n",
      " horrible: -1.7964\n",
      " crap: -1.7379\n",
      " terrible: -1.686\n",
      " stupid: -1.6793\n",
      " bad,: -1.677\n"
     ]
    }
   ],
   "source": [
    "print(\"Words Most Likely in Negative Reviews:\")\n",
    "print(\"\")\n",
    "\n",
    "indices = np.argsort(nb_w)\n",
    "\n",
    "for i in indices[:10]:\n",
    "    print(f\" {vocabulary[i]}: {round(nb_w[i], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "genetic-bumper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words Most Likely in Positive Reviews:\n",
      "\n",
      " perfectly: 1.2845\n",
      " perfect: 1.2881\n",
      " loved: 1.3188\n",
      " brilliant: 1.3455\n",
      " powerful: 1.3764\n",
      " amazing: 1.4578\n",
      " superb: 1.5322\n",
      " excellent: 1.5671\n",
      " wonderful: 1.5835\n",
      " fantastic: 1.5851\n"
     ]
    }
   ],
   "source": [
    "print(\"Words Most Likely in Positive Reviews:\")\n",
    "print(\"\")\n",
    "\n",
    "for i in indices[-10:]:\n",
    "    print(f\" {vocabulary[i]}: {round(nb_w[i], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c86dfa",
   "metadata": {},
   "source": [
    "## II. SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f92c1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm = svm.LinearSVC(max_iter=10000, dual=False).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461e4c0",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "83e0308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Train Accuracy: 88.536%\n"
     ]
    }
   ],
   "source": [
    "linear_svm_train_predictions = linear_svm.predict(X_train)\n",
    "linear_svm_train_accuracy = (linear_svm_train_predictions == Y_train).mean()\n",
    "\n",
    "print(f\"Linear SVM Train Accuracy: {linear_svm_train_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0a8f1",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2aaa4201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Test Accuracy: 84.544%\n"
     ]
    }
   ],
   "source": [
    "linear_svm_test_predictions = linear_svm.predict(X_test)\n",
    "linear_svm_test_accuracy = (linear_svm_test_predictions == Y_test).mean()\n",
    "\n",
    "print(f\"Linear SVM Test Accuracy: {linear_svm_test_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-cooler",
   "metadata": {},
   "source": [
    "## IV. LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c10d57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(\n",
    "    random_state=0,\n",
    "    solver='liblinear'\n",
    ").fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cd9b36",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c512997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Accuracy: 88.75999999999999%\n"
     ]
    }
   ],
   "source": [
    "logreg_train_predictions = logreg.predict(X_train)\n",
    "logreg_train_accuracy = (logreg_train_predictions == Y_train).mean()\n",
    "\n",
    "print(f\"Logistic Regression Train Accuracy: {logreg_train_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-level",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c316aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 84.608%\n"
     ]
    }
   ],
   "source": [
    "logreg_test_predictions = logreg.predict(X_test)\n",
    "logreg_test_accuracy = (logreg_test_predictions == Y_test).mean()\n",
    "\n",
    "print(f\"Logistic Regression Test Accuracy: {logreg_test_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a4040",
   "metadata": {},
   "source": [
    "# PART 2 - Bigger Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e042aa",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e977013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Loaded\n"
     ]
    }
   ],
   "source": [
    "train_data_big_voc = np.loadtxt(\"big_voc_train.txt.gz\")\n",
    "X_train_big_voc = train_data_big_voc[:, :-1]\n",
    "Y_train_big_voc = train_data_big_voc[:, -1]\n",
    "\n",
    "print(\"Train Data Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "810c7b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Loaded\n"
     ]
    }
   ],
   "source": [
    "test_data_big_voc = np.loadtxt(\"big_voc_test.txt.gz\")\n",
    "X_test_big_voc = test_data_big_voc[:, :-1]\n",
    "Y_test_big_voc = test_data_big_voc[:, -1]\n",
    "\n",
    "print(\"Test Data Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c25ce",
   "metadata": {},
   "source": [
    "## I. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9a0e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained\n"
     ]
    }
   ],
   "source": [
    "nb_w_big_voc, nb_b_big_voc = train_nb(X_train_big_voc, Y_train_big_voc)\n",
    "\n",
    "print(\"Classifier trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e931486",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684a65be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training Accuracy: 81.76%\n"
     ]
    }
   ],
   "source": [
    "nb_train_predictions_big_voc = inference_nb(X_train_big_voc, nb_w_big_voc, nb_b_big_voc)\n",
    "nb_train_accuracy_big_voc = (nb_train_predictions_big_voc == Y_train_big_voc).mean()\n",
    "\n",
    "print(f\"Naive Bayes Training Accuracy: {nb_train_accuracy_big_voc * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d7459",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3754274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Testing Accuracy: 80.56%\n"
     ]
    }
   ],
   "source": [
    "nb_test_predictions_big_voc = inference_nb(X_test_big_voc, nb_w_big_voc, nb_b_big_voc)\n",
    "nb_test_accuracy_big_voc = (nb_test_predictions_big_voc == Y_test_big_voc).mean()\n",
    "\n",
    "print(f\"Naive Bayes Testing Accuracy: {nb_test_accuracy_big_voc * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bd3dc",
   "metadata": {},
   "source": [
    "## II. SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e61ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_big_voc = svm.LinearSVC(\n",
    "    max_iter=10000,\n",
    "    dual=False\n",
    ").fit(X_train_big_voc, Y_train_big_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652d878",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d2d9a861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Train Accuracy: 90.58800000000001%\n"
     ]
    }
   ],
   "source": [
    "linear_svm_train_predictions_big_voc = linear_svm_big_voc.predict(X_train_big_voc)\n",
    "linear_svm_train_accuracy_big_voc = (linear_svm_train_predictions_big_voc == Y_train_big_voc).mean()\n",
    "\n",
    "print(f\"Linear SVM Train Accuracy: {linear_svm_train_accuracy_big_voc * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f40915a",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "57083849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Test Accuracy: 86.36%\n"
     ]
    }
   ],
   "source": [
    "linear_svm_test_predictions_big_voc = linear_svm_big_voc.predict(X_test_big_voc)\n",
    "linear_svm_test_accuracy_big_voc = (linear_svm_test_predictions_big_voc == Y_test_big_voc).mean()\n",
    "\n",
    "print(f\"Linear SVM Test Accuracy: {linear_svm_test_accuracy_big_voc * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f5106",
   "metadata": {},
   "source": [
    "## III. LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b4ee6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_big_voc = LogisticRegression(\n",
    "    random_state=0,\n",
    "    solver='liblinear'\n",
    ").fit(X_train_big_voc, Y_train_big_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360c447",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17eef05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Accuracy: 90.768%\n"
     ]
    }
   ],
   "source": [
    "logreg_train_predictions_big_voc = logreg_big_voc.predict(X_train_big_voc)\n",
    "logreg_train_accuracy_big_voc = (logreg_train_predictions_big_voc == Y_train_big_voc).mean()\n",
    "\n",
    "print(f\"Logistic Regression Train Accuracy: {logreg_train_accuracy_big_voc * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e82d58",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b446aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 86.37599999999999%\n"
     ]
    }
   ],
   "source": [
    "logreg_test_predictions_big_voc = logreg_big_voc.predict(X_test_big_voc)\n",
    "logreg_test_accuracy_big_voc = (logreg_test_predictions_big_voc == Y_test_big_voc).mean()\n",
    "\n",
    "print(f\"Logistic Regression Test Accuracy: {logreg_test_accuracy_big_voc * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea77599",
   "metadata": {},
   "source": [
    "# PART 3 - STEMMED DATA WITHOUT STOPWORDS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd15d425",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da43b88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Loaded\n"
     ]
    }
   ],
   "source": [
    "train_data_stem_sw = np.loadtxt(\"train_stem_sw.txt.gz\")\n",
    "X_train_stem_sw = train_data_stem_sw[:, :-1]\n",
    "Y_train_stem_sw = train_data_stem_sw[:, -1]\n",
    "\n",
    "print(\"Train Data Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d5cc968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Loaded\n"
     ]
    }
   ],
   "source": [
    "test_data_stem_sw = np.loadtxt(\"test_stem_sw.txt.gz\")\n",
    "X_test_stem_sw = test_data_stem_sw[:, :-1]\n",
    "Y_test_stem_sw = test_data_stem_sw[:, -1]\n",
    "\n",
    "print(\"Test Data Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec0fedb",
   "metadata": {},
   "source": [
    "## I. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80e9e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained\n"
     ]
    }
   ],
   "source": [
    "nb_w_stem_sw, nb_b_stem_sw = train_nb(X_train_stem_sw, Y_train_stem_sw)\n",
    "\n",
    "print(\"Classifier trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b1d4c4",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69cc3def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training Accuracy: 79.104%\n"
     ]
    }
   ],
   "source": [
    "nb_train_predictions_stem_sw = inference_nb(X_train_stem_sw, nb_w_stem_sw, nb_b_stem_sw)\n",
    "nb_train_accuracy_stem_sw = (nb_train_predictions_stem_sw == Y_train_stem_sw).mean()\n",
    "\n",
    "print(f\"Naive Bayes Training Accuracy: {nb_train_accuracy_stem_sw * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c0f13",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3a7f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Testing Accuracy: 77.656%\n"
     ]
    }
   ],
   "source": [
    "nb_test_predictions_stem_sw = inference_nb(X_test_stem_sw, nb_w_stem_sw, nb_b_stem_sw)\n",
    "nb_test_accuracy_stem_sw = (nb_test_predictions_stem_sw == Y_test_stem_sw).mean()\n",
    "\n",
    "print(f\"Naive Bayes Testing Accuracy: {nb_test_accuracy_stem_sw * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed911f37",
   "metadata": {},
   "source": [
    "## II. SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "17b28152",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_stem_sw = svm.LinearSVC(\n",
    "    max_iter=10000,\n",
    "    dual=False\n",
    ").fit(X_train_stem_sw, Y_train_stem_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c2aff8",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ece11478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Train Accuracy: 82.50800000000001%\n"
     ]
    }
   ],
   "source": [
    "linear_svm_train_predictions_stem_sw = linear_svm_stem_sw.predict(X_train_stem_sw)\n",
    "linear_svm_train_accuracy_stem_sw = (linear_svm_train_predictions_stem_sw == Y_train_stem_sw).mean()\n",
    "\n",
    "print(f\"Linear SVM Train Accuracy: {linear_svm_train_accuracy_stem_sw * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b78d1",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bc0dc00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Test Accuracy: 80.264%\n"
     ]
    }
   ],
   "source": [
    "linear_svm_test_predictions_stem_sw = linear_svm_stem_sw.predict(X_test_stem_sw)\n",
    "linear_svm_test_accuracy_stem_sw = (linear_svm_test_predictions_stem_sw == Y_test_stem_sw).mean()\n",
    "\n",
    "print(f\"Linear SVM Test Accuracy: {linear_svm_test_accuracy_stem_sw * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd137db8",
   "metadata": {},
   "source": [
    "## III. LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "02eb70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_stem_sw = LogisticRegression(\n",
    "    random_state=0,\n",
    "    solver='liblinear'\n",
    ").fit(X_train_stem_sw, Y_train_stem_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8fe03d",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ce824ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Accuracy: 82.628%\n"
     ]
    }
   ],
   "source": [
    "logreg_train_predictions_stem_sw = logreg_stem_sw.predict(X_train_stem_sw)\n",
    "logreg_train_accuracy_stem_sw = (logreg_train_predictions_stem_sw == Y_train_stem_sw).mean()\n",
    "\n",
    "print(f\"Logistic Regression Train Accuracy: {logreg_train_accuracy_stem_sw * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e250ac",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12b749d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 80.432%\n"
     ]
    }
   ],
   "source": [
    "logreg_test_predictions_stem_sw = logreg_stem_sw.predict(X_test_stem_sw)\n",
    "logreg_test_accuracy_stem_sw = (logreg_test_predictions_stem_sw == Y_test_stem_sw).mean()\n",
    "\n",
    "print(f\"Logistic Regression Test Accuracy: {logreg_test_accuracy_stem_sw * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2ad1ab",
   "metadata": {},
   "source": [
    "# PART 4 - ACCURACY COMPARISON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb22204",
   "metadata": {},
   "source": [
    "### Training Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7a5edfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal Data</th>\n",
       "      <th>Data with Bigger Vocabulary</th>\n",
       "      <th>Stemmed Data without Stopwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifiers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>80.03%</td>\n",
       "      <td>81.76%</td>\n",
       "      <td>79.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nu-SVM</th>\n",
       "      <td>88.54%</td>\n",
       "      <td>90.59%</td>\n",
       "      <td>82.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>88.75%</td>\n",
       "      <td>90.77%</td>\n",
       "      <td>82.63%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Normal Data Data with Bigger Vocabulary  \\\n",
       "Classifiers                                                   \n",
       "Naive Bayes              80.03%                      81.76%   \n",
       "Nu-SVM                   88.54%                      90.59%   \n",
       "Logistic Regression      88.75%                      90.77%   \n",
       "\n",
       "                    Stemmed Data without Stopwords  \n",
       "Classifiers                                         \n",
       "Naive Bayes                                 79.10%  \n",
       "Nu-SVM                                      82.50%  \n",
       "Logistic Regression                         82.63%  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    'Normal Data':[\"80.03%\", \"88.54%\", \"88.75%\"],\n",
    "    'Data with Bigger Vocabulary':[\"81.76%\", \"90.59%\", \"90.77%\"],\n",
    "    'Stemmed Data without Stopwords':[\"79.10%\", \"82.50%\", \"82.63%\"],\n",
    "    'Classifiers': [\"Naive Bayes\", \"Nu-SVM\", \"Logistic Regression\"]\n",
    "}\n",
    "\n",
    "print(\"Training Accuracies\")\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df.set_index('Classifiers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa03f5",
   "metadata": {},
   "source": [
    "### Testing Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "superb-circulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal Data</th>\n",
       "      <th>Data with Bigger Vocabulary</th>\n",
       "      <th>Stemmed Data without Stopwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifiers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>79.76%</td>\n",
       "      <td>80.56%</td>\n",
       "      <td>77.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nu-SVM</th>\n",
       "      <td>84.54%</td>\n",
       "      <td>86.36%</td>\n",
       "      <td>80.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>84.61%</td>\n",
       "      <td>86.38%</td>\n",
       "      <td>80.43%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Normal Data Data with Bigger Vocabulary  \\\n",
       "Classifiers                                                   \n",
       "Naive Bayes              79.76%                      80.56%   \n",
       "Nu-SVM                   84.54%                      86.36%   \n",
       "Logistic Regression      84.61%                      86.38%   \n",
       "\n",
       "                    Stemmed Data without Stopwords  \n",
       "Classifiers                                         \n",
       "Naive Bayes                                 77.66%  \n",
       "Nu-SVM                                      80.26%  \n",
       "Logistic Regression                         80.43%  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    'Normal Data':[\"79.76%\", \"84.54%\", \"84.61%\"],\n",
    "    'Data with Bigger Vocabulary':[\"80.56%\", \"86.36%\", \"86.38%\"],\n",
    "    'Stemmed Data without Stopwords':[\"77.66%\", \"80.26%\", \"80.43%\"],\n",
    "    'Classifiers': [\"Naive Bayes\", \"Nu-SVM\", \"Logistic Regression\"]\n",
    "}\n",
    "\n",
    "print(\"Testing Accuracies\")\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df.set_index('Classifiers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42795b5",
   "metadata": {},
   "source": [
    "# PART 5 - EXAMPLE OF A SARCASTIC REVIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b03bf",
   "metadata": {},
   "source": [
    "## a) Initialization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426ad75",
   "metadata": {},
   "source": [
    "#### Vocabulary with Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d4d07377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocabulary_with_indices(filename):\n",
    "    f = open(filename, encoding=\"utf-8\")\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    words = text.split()\n",
    "    \n",
    "    # Create index for each word\n",
    "    voc = {}\n",
    "    index = 0\n",
    "    for word in words:\n",
    "        voc[word] = index\n",
    "        index += 1\n",
    "    \n",
    "    return voc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409648c",
   "metadata": {},
   "source": [
    "#### Split Document into BoW Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59201c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT = \"!#$%&()''*+-/.:;?@[]{}|^_`~<>=\\\"\" # all punctuation we discard\n",
    "TABLE = str.maketrans(PUNCT, \" \" * len(PUNCT)) # replace punctuation by space\n",
    "\n",
    "def txt_as_bow(filename, voc):\n",
    "    f = open(filename, encoding=\"utf-8\") # specify encoding to avoid unreadable documents\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    text = text.lower() # all words to lowercase\n",
    "    text = text.translate(TABLE)\n",
    "    words = text.split() # separate the document into list of words\n",
    "    \n",
    "    # Bag of Words\n",
    "    bow = np.zeros(len(voc))\n",
    "    for word in words:\n",
    "        if word in voc:\n",
    "            index = voc[word]\n",
    "            bow[index] += 1\n",
    "    \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d79faf7",
   "metadata": {},
   "source": [
    "#### Display Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "806f5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_text_document(filename, pos=False,):\n",
    "    \n",
    "    if pos == True:\n",
    "        path = glob.glob(\"aclImdb/test/pos/*.txt\")\n",
    "    else:\n",
    "        path = glob.glob(\"aclImdb/test/neg/*.txt\")\n",
    "    f = open(path[filename], encoding=\"utf-8\") # specify encoding to avoid unreadable documents\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    text = text.replace(\"<br /><br />\", \"\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329742bd",
   "metadata": {},
   "source": [
    "## b) Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4e6d1d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb/test/neg\\10066_1.txt\n",
      "\n",
      "Prediction: [0] , Real Class: [1.]\n",
      "\n",
      "Looking for a REAL super bad movie? If you wanna have great fun, don't hesitate and check this one!Ferrigno is incredibly bad but is also the best of this mediocrity.\n"
     ]
    }
   ],
   "source": [
    "vocabulary_with_indices = load_vocabulary_with_indices(\"vocabulary.txt\")\n",
    "documents_37 = []\n",
    "labels_37 = []\n",
    "\n",
    "path_neg_37 = glob.glob(\"aclImdb/test/neg/*.txt\")[37]     # negative review number 38 in the test dataset \n",
    "bow_37 = txt_as_bow(path_neg_37, vocabulary_with_indices) # BoW representation of the review\n",
    "\n",
    "documents_37.append(bow_37)\n",
    "labels_37.append(1)\n",
    "labels_37 = np.array(labels_37)\n",
    "\n",
    "data_37 = np.concatenate([\n",
    "    documents_37,\n",
    "    labels_37[:, None]\n",
    "],1)\n",
    "\n",
    "X_37 = data_37[:, :-1]\n",
    "Y_37 = data_37[:, -1]\n",
    "\n",
    "prediction_37 = inference_nb(X_37, nb_w, nb_b)\n",
    "\n",
    "print(path_neg_37)\n",
    "print(\"\")\n",
    "\n",
    "print(f\"Prediction: {prediction_37} , Real Class: {Y_37}\")\n",
    "print(\"\")\n",
    "\n",
    "print(display_text_document(37))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-blink",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
